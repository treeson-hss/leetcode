# 链表
>LRU 缓存淘汰算法
常见缓存淘汰策略
> - 先进先出策略 FIFO（First In，First Out）
> - 最少使用策略 LFU（Least Frequently Used）
> - 最近最少使用策略 LRU（Least Recently Used）

## 底层数据结构
链表和数组相反，其并不需要一块连续的内存空间，它通过“指针”将一组零散的内存块串联起来使用

## 单链表
内存块称为链表的“结点”。为了将所有的结点串起来，每个链表的结点除了存储数据之外，还需要记录链上的下一个结点的地址。把这个记录下个结点地址的指针叫作后继指针 next。
- 单链表中，有两个结点是比较特殊的，它们分别是第一个结点和最后一个结点。习惯性地把第一个结点叫作头结点，把最后一个结点叫作尾结点。
- 其中，头结点用来记录链表的基地址。有了它，我们就可以遍历得到整条链表。而尾结点特殊的地方是：指针不是指向下一个结点，而是指向一个空地址 NULL，表示这是链表上最后一个结点。

## 循环链表

循环链表是一种特殊的单链表。实际上，循环链表也很简单。它跟单链表唯一的区别就在尾结点。循环链表的尾结点指针是指向链表的头结点。

## 双向链表
双向链表，顾名思义，它支持两个方向，每个结点不止有一个后继指针 next 指向后面的结点，还有一个前驱指针 prev 指向前面的结点。

双向链表需要额外的两个空间来存储后继结点和前驱结点的地址。

## 单链表与双向链表
- 单向链表只有一个方向，结点只有一个后继指针 next 指向后面的结点。如果存储同样多的数据，双向链表要比单链表占用更多的内存空间。
- 双向链表可以支持双向遍历，支持 O(1) 时间复杂度的情况下找到前驱结点，使双向链表在某些情况下的插入、删除等操作都要比单链表简单、高效。
- 用空间换时间

### 删除操作
链表的删除操作主要包括：
- 删除结点中“值等于某个给定值”的结点
- 删除给定指针指向的结点。

#### 删除结点中“值等于某个给定值”的结点
这种情况下，不管是单链表还是双向链表，为了查找到值等于给定值的结点，都需要从头结点开始一个一个依次遍历对比，直到找到值等于给定值的结点，然后再通过O(1)的指针操作将其删除。

尽管单纯的删除操作时间复杂度是 O(1)，但遍历查找的时间是主要的耗时点，对应的时间复杂度为 O(n)。根据时间复杂度分析中的加法法则，删除值等于给定值的结点对应的链表操作的总时间复杂度为 O(n)。

#### 删除给定指针指向的结点。
这种情况下，如果已经找到了要删除的结点，但是删除某个结点 q 需要知道其前驱结点。
而单链表并不支持直接获取前驱结点，所以，为了找到前驱结点，还是要从头结点开始遍历链表，直到 p->next=q，说明 p 是 q 的前驱结点。
但是对于双向链表来说，这种情况就比较有优势了。因为双向链表中的结点已经保存了前驱结点的指针，不需要像单链表那样遍历。
所以，针对这种情况，单链表删除操作需要 O(n) 的时间复杂度，而双向链表只需要在 O(1) 的时间复杂度内就搞定了！

### 插入操作

#### 在链表的某个指定结点前面插入一个结点
同理，双向链表比单链表有很大的优势。双向链表可以在 O(1) 时间复杂度搞定，而单向链表需要 O(n) 的时间复杂度。

### 查询操作
#### 有序链表
对于一个有序链表，双向链表的按值查询的效率也要比单链表高一些。因为，我们可以记录上次查找的位置 p，每次查询时，根据要查找的值与 p 的大小关系，决定是往前还是往后查找，所以平均只需要查找一半的数据。

## 链表 VS 数组

- 因为内存存储的区别，它们插入、删除、随机访问操作的时间复杂度正好相反。和数组相比，链表更适合插入、删除操作频繁的场景，查询的时间复杂度较高。
- 数组简单易用，在实现上使用的是连续的内存空间，可以借助 CPU 的缓存机制，预读数组中的数据，所以访问效率更高。而链表在内存中并不是连续存储，所以对 CPU 缓存不友好，没办法有效预读。
> CPU缓存制度：CPU在从内存读取数据的时候，会先把读取到的数据加载到CPU的缓存中。而CPU每次从内存读取数据并不是只读取那个特定要访问的地址，而是读取一个数据块(也可以说一整个缓存行，看操作系统位数决定。Cache Line 是 Cache 与 DRAM 同步的最小单位. 典型的虚拟内存页面大小为 4KB,而典型的 Cache line 通常的大小为 32 或 64 字节)并保存到CPU缓存中，然后下次访问内存数据的时候就会先从CPU缓存开始查找，如果找到就不需要再从内存中取。这样就实现了比内存访问速度更快的机制，也就是CPU缓存存在的意义:为了弥补内存访问速度过慢与CPU执行速度快之间的差异而引入。
对于数组来说，存储空间是连续的，所以在加载某个下标的时候可以把以后的几个下标元素也加载到CPU缓存这样执行速度会快于存储空间不连续的链表存储。
- 数组的缺点是大小固定，一经声明就要占用整块连续内存空间。如果声明的数组过大，系统可能没有足够的连续内存空间分配给它，导致“内存不足（out of memory）”。如果声明的数组过小，则可能出现不够用的情况。这时只能再申请一个更大的内存空间，把原数组拷贝进去，非常费时。链表本身没有大小的限制，天然地支持动态扩容，这也是它与数组最大的区别。

## 实现 LRU 缓存淘汰算法
### 基于链表实现
维护一个有序单链表，越靠近链表尾部的结点是越早之前访问的。当有一个新的数据被访问时，我们从链表头开始顺序遍历链表。
1. 如果此数据之前已经被缓存在链表中了，我们遍历得到这个数据对应的结点，并将其从原来的位置删除，然后再插入到链表的头部。
2. 如果此数据没有在缓存链表中，又可以分为两种情况
- 如果此时缓存未满，则将此结点直接插入到链表的头部
- 如果此时缓存已满，则链表尾结点删除，将新的数据结点插入链表的头部。

#### 时间复杂度计算
因为不管缓存有没有满，我们都需要遍历一遍链表，所以这种基于链表的实现思路，缓存访问的时间复杂度为 O(n)。

实际上，可以继续优化这个实现思路，比如引入散列表（Hash table）来记录每个数据的位置，将缓存访问的时间复杂度降到 O(1)。

## 基于链表实现回文字符串判断
> 如果字符串是通过单链表来存储的，那该如何来判断是一个回文串呢？

**思路一** 
使用快慢两个指针找到链表中点，慢指针每次前进一步，快指针每次前进两步。
在慢指针前进的过程中，同时修改其 next 指针，使得链表前半部分反序。
最后比较中点两侧的链表是否相等。
JAVA代码实现：
```java
/**
 * Definition for singly-linked list.
 * public class ListNode {
 *     int val;
 *     ListNode next;
 *     ListNode(int x) { val = x; }
 * }
 */
class Solution {
  public boolean isPalindrome(ListNode head) {
    if (head == null || head.next == null) {
      return true;
    }

    ListNode prev = null;
    ListNode slow = head;
    ListNode fast = head;

    while (fast != null && fast.next != null) {
      fast = fast.next.next;
      ListNode next = slow.next;
      slow.next = prev;
      prev = slow;
      slow = next;
    }

    if (fast != null) {
      slow = slow.next;
    }

    while (slow != null) {
      if (slow.val != prev.val) {
        return false;
      }
      slow = slow.next;
      prev = prev.next;
    }

    return true;
  }
}
```


**思路二**
1. 快慢指针定位中间节点（这里要区分奇偶情况）
1.1 奇数情况，中点位置不需要矫正
1.2 偶数情况，使用偶数定位中点策略，要确定是返回上中位数或下中位数
1.2.1 如果是返回上中位数，后半部分串头取next
1.2.2 如果是返回下中位数，后半部分串头既是当前节点位置，但前半部分串尾要删除掉当前节点
2. 从中间节点对后半部分逆序，或者将前半部分逆序
3. 一次循环比较，判断是否为回文
4. 恢复现场

时间复杂度：O(n)
空间复杂度：O(1)

